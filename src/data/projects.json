{
    "chasse-matignon": {
        "id": "chasse-matignon",
        "title": "Chasse Matignon",
        "description": "Chasse matignon was a website we did to centralize all the tweets of the french politicians that said they were ready to be prime minister after the 2024 elections.",
        "shortDescription": "Chasse matignon was a website we did to centralize all the tweets of the french politicians that said they were ready to be prime minister after the 2024 elections.",
        "detailedDescription": "Chasse matignon was a website we did to centralize all the tweets of the french politicians that said they were ready to be prime minister after the 2024 elections. The website displayed a quizz with a random french political figure, and asked you if he published a tweet saying he was ready to be called prime minister by Emmanuel Macron, and then you had your answer, with the embedded tweet if it existed.",
        "category": "Website",
        "categoryClass": "badge-primary",
        "gradient": "linear-gradient(135deg, #059669 0%, #065f46 100%)",
        "image": "/images/projects/matignon.jpg",
        "technologies": ["React", "Typescript", "Twitter API"],
        "year": "2025",
        "github": "https://github.com/tomasoignons/chasse-matignon",
        "demo": null,
        "externalLink": null,
        "status": "Completed",
        "features": [
        "Random quizz with french political figures and their tweets about being prime minister",
        "Displaying tweets inside a web application"
        ],
        "technicalDetails": "After the 2024 assembly elections in France, the resulting assembly was splited in 3 clear blocks, who each had between 28 and 35% of the seats. A lot of policians, from any polical boards, claimed they were the right person to be chosen as prime minister. There were more than 3 people saying Emmanuel Macron should name them. As a joke, with two friends, we started to say it would be funny to have a website to see if random political figures said they were 'ready to be called', or that they were 'really well placed to be chosen'. It randomly selects a politician and checks the system config files for any existing tweets. The website uses the Twitter API to fetch tweets from a predefined list of French political figures, to display it to the user. The frontend is built with React and Typescript, ensuring a responsive and interactive user experience.",
        "impact": "It was really fun to work on this project, and see completely random people trying to be the next prime minister of France, even if they had no chance at all.",
        "customComponent": false,
        "objectFit": "object-cover"
  },
    "legipredi": {
        "id": "legipredi",
        "title": "LegiPredi",
        "description": "Legi Predi is a project were I analyzed the data from The previous French elections, and tried to predict the results of the 2024 elections.",
        "shortDescription": "Legi Predi is a project were I analyzed the data from The previous French elections, and tried to predict the results of the 2024 elections.",
        "detailedDescription": "Legi Predi is a project where I analyzed the data from the previous French elections and tried to predict the results of the 2024 elections. The project involved collecting and processing election data, building predictive models, and visualizing the results.",
        "category": "Data Analysis",
        "categoryClass": "badge-primary",
        "gradient": "linear-gradient(135deg, #059669 0%, #065f46 100%)",
        "image": "/images/projects/legipredi.jpg",
        "technologies": ["Python", "Pandas", "Matplotlib", "Jupyter Notebooks", "Data Processing", "Data collection"],
        "year": "2025",
        "github": "https://github.com/tomasoignons/legislatives-2024",
        "demo": null,
        "externalLink": null,
        "status": "Completed",
        "features": [
        "Analyzing previous election data",
        "Building predictive models",
        "Visualizing election results"
        ],
        "technicalDetails": "In June 2024, after the Europeans elections, Emmanuel Macron called for new legislative elections. The country was divided, and the result announced to be extremely close. I tried to gather the electoral data from the previous elections, then I processed it with Python and Pandas to match the legislatives constituencies. I wanted mainly to work with the previous legislative election data (2022), and the result of the european election that just occured. The issue was that the voting system in France is a bit weird for legislative elections, so I had to map each vote office to count the right number of votes in each constituency. Then, I made a 3 layer matrix to know who will deport to whom at the end of the first round, and to the third. With my custom analysis, I predicted the results of the first round better than any sondage institution. For the second round, I only focused on using the data of the first round, with a decision matrix to simulate the voting report in each circonscriptions. I again managed to predict at a 2% margin error the results, better than any predictions made by the medias and journalists. To vizualize, I made some comprehensive plot using matplotlib.",
        "impact": "When I published my results on Instagram, I got full attention of most of my followers, who were really impressed by the accuracy of my predictions. It did not have any impact on the elections, but next time, I will try to make it more visible to the policial parties and medias, as it can helps with the strategy for the second round (alliances, etc).",
        "customComponent": false,
        "objectFit": "object-cover"
  },
    "minube": {
        "id": "minube",
        "title": "Minube",
        "description": "For a startup Contest, I created a startup to create a plateform to create a marketplace for miniamakers to sell their services.",
        "shortDescription": "For a startup Contest, I created a startup to create a plateform to create a marketplace for miniamakers to sell their services.",
        "detailedDescription": "Each year, Start, an association, organised a Startup Contest, where you have to pass multiple rounds of presentations, to get to the final and finally win a cash prize to help you with your project. This project was made for the 2024-2025 edition, where I arrived in the semi-finals. The idea was to create a marketplace for miniamakers, that are people who create miniatures, to sell their services. The platform would allow them to create a profile, and sell their services to the youtubers that will need them for their youtube videos.",
        "category": "Startup",
        "categoryClass": "badge-primary",
        "gradient": "linear-gradient(135deg, #059669 0%, #065f46 100%)",
        "image": "/images/projects/minube.jpg",
        "technologies": ["Vue.js", "Supabase", "Tailwind CSS", "Stripe"],
        "year": "2025",
        "github": "https://github.com/tomasoignons/minube",
        "demo": null,
        "externalLink": null,
        "status": "Completed",
        "features": [
        "Marketplace for miniamakers to sell their services",
        "Account creation and profile management",
        "Picture storage in Database",
        "User uploadable content management system",
        "Payment management system with Stripe integration"
        ],
        "technicalDetails": "The website was really interesting to learn, and it is also one of the first project I did using the supabase database. The frontend is built with Vue.js and Tailwind CSS, ensuring a responsive and interactive user experience. The backend is powered by Supabase, which provides a robust and scalable database solution. For payment processing, I integrated Stripe to handle transactions securely and efficiently.",
        "impact": "With this project, as well as the business model or value proposition, I managed to go into the semi-finals of the 2024-2025 biggest Startup Contest in Switzerland.",
        "customComponent": false,
        "objectFit": "object-cover"
  },
    "wgzimmer-bot": {
        "id": "wgzimmer-bot",
        "title": "WG Zimmer Bot",
        "description": "When I moved in Zürich for my exchange year, I discovered the housing market in Zürich. Less than 200 flats are available for a city of more than 400,000 inhabitants. I created a bot to help me find a flat more easily.",
        "shortDescription": "When I moved in Zürich for my exchange year, I discovered the housing market in Zürich. Less than 200 flats are available for a city of more than 400,000 inhabitants. I created a bot to help me find a flat more easily.",
        "detailedDescription": "When I moved to Zürich for my exchange year, I quickly realized that the housing market was extremely competitive, with fewer than 200 flats available in a city of over 400,000 inhabitants. To improve my chances of finding a suitable flat, I developed a bot that automatically searches for new listings on WG Zimmer and automaticaly applies. This tool significantly streamlined my search process and helped me secure accommodation in a challenging market.",
        "category": "Bots",
        "categoryClass": "badge-primary",
        "gradient": "linear-gradient(135deg, #059669 0%, #065f46 100%)",
        "image": "/images/projects/wgzimmer-bot.jpg",
        "technologies": ["Python", "Selenium", "Web Scraping", "Automation", "Google Captcha Bypass"],
        "year": "2025",
        "github": null,
        "demo": null,
        "externalLink": null,
        "status": "Completed",
        "features": [
          "Auto Verifications of the new listing on WG Zimmer",
          "Automatic application submission to new listings",
          "Bypassing Google Captcha with using specialised techniques",
          "e-mail notification when a new flat is found",
          "Self hosting on a custom mini-PC to bypass Google Captcha limitations"
        ],
        "technicalDetails": "I started automating the wgzimmer applications with Selenium, and it turns out it is not possible to do otherwise, because of the Google Recaptcha system implemented. I had to twist the parameters of the system to make it work fine, and I plugged in the chatGPT OPenAI API, so that the bot could do custom applications everytime he encountered an offer that matched my criterias.",
        "impact": "The bot made more than 150 applications, and I recieved a 10% response rate. When I was doing it manually, I often arrived too late, so I only had a 2% response rate.",
        "customComponent": false,
        "objectFit": "object-cover"
  },
    "coolstreet": {
        "id": "coolstreet",
        "title": "Coolstreet",
        "description": "For my Sustrainable Entrepreneurship Class, we had to develop a Startup idea to solve a city problem in sustainability. We created Coolstreet, an infrastructure plateform to make them more sustainable.",
        "shortDescription": "For my Sustrainable Entrepreneurship Class, we had to develop a Startup idea to solve a city problem in sustainability. We created Coolstreet, an infrastructure company to help city reduce heatwaves impact.",
        "detailedDescription": "For my Sustrainable Entrepreneurship Class, we had to develop a Startup idea to solve a city problem in sustainability. With a group of 5 people, we created Coolstreet, an infrastructure plateform to make them more sustainable.",
        "category": "Startup",
        "categoryClass": "badge-primary",
        "gradient": "linear-gradient(135deg, #059669 0%, #065f46 100%)",
        "image": null,
        "technologies": ["TeamWork", "Vue.js", "Business Model Creation", "Speaking in Public"],
        "year": "2025",
        "github": "https://github.com/tomasoignons/website-coolstreet",
        "demo": null,
        "externalLink": null,
        "status": "Completed",
        "features": [
        "Functional Website presenting the project",
        "Business Plan creation",
        "Group collaboration and teamwork"
        ],
        "technicalDetails": "The website is coded in VueJS, and was used for the final presentation",
        "impact": "We got one of the best grade of the class for this project.",
        "customComponent": false
  },
    "ricardo-bot": {
        "id": "ricardo-bot",
        "title": "Ricardo Bot",
        "description": "I often use Ricardo, which is an auction website in Switzerland. Sometimes, an auction don't get any single bid, and you can get really good deals. I made a bot that sent me a notification when I can get a really good deal on an item.",
        "shortDescription": "I often use Ricardo, which is an auction website in Switzerland. Sometimes, an auction don't get any single bid, and you can get really good deals. I made a bot that sent me a notification when I can get a really good deal on an item.",
        "detailedDescription": "I often use Ricardo, which is an auction website in Switzerland. Sometimes, an auction don't get any single bid, and you can get really good deals. I made a bot that checks the auctions that are gonna close in the next hour, ask chatGPT how much will be the fair value of the object, and warns me if it is less than 30% of the fair value.",
        "category": "Bots",
        "categoryClass": "badge-primary",
        "gradient": "linear-gradient(135deg, #059669 0%, #065f46 100%)",
        "image": "/images/projects/ricardo.png",
        "technologies": ["Cloudflare ByPass", "Requests", "Python Automation", "Telegram Bot", "Notification System"],
        "year": "2025",
        "github": null,
        "demo": null,
        "externalLink": null,
        "status": "Completed",
        "features": [
        "TBD"
        ],
        "technicalDetails": "TBD",
        "impact": "TBD",
        "customComponent": false
  },
    "arbitrage-betting": {
        "id": "arbitrage-betting",
        "title": "Arbitrage Betting",
        "description": "I love to imagine mathematical way of winning on bettings. And sometimes, you can. By betting on different bookmarkers, you can have a return on investment that is more than 100% on sport betting.",
        "shortDescription": "I love to imagine mathematical way of winning on bettings.",
        "detailedDescription": "The artbitrage betting is a betting technique that consists to bet on two different outcomes of a bet in two different bookmakers. Because the bookmakers don't have the same odds, you can find opportunities where the combined odds allow for a guaranteed profit. By betting on different bookmarkers, you can have a return on investment that is more than 100% on sport betting. I tried to setup a bot that will notify me as soon as such an opportunity exists on the French market.",
        "category": "Bots",
        "categoryClass": "badge-primary",
        "gradient": "linear-gradient(135deg, #059669 0%, #065f46 100%)",
        "image": "/images/projects/arbitrage-betting.jpeg",
        "technologies": ["Automation", "Web Scraping", "Data Analysis", "Betting Strategies", "Database optimization"],
        "year": "2025",
        "github": null,
        "demo": null,
        "externalLink": null,
        "status": "Completed",
        "features": [
        "Automatic fetching of odds from multiple bookmakers",
        "Identifying arbitrage opportunities",
        "Notification system to alert when an opportunity is found",
        "More than 400 types of bets supported"
        ],
        "technicalDetails": "The bookmakers often don't propose an open API. To fetch their data, you have to reverse ingeneer their apps or websites. Some of them use the same provider, but with different margins. The bot is made in Python, and uses requests to fetch the data, and beautifulsoup to parse the HTML. The data is stored in a local database, and analyzed to find arbitrage opportunities. The bot can find more than 400 types of bets, and is able to notify me when an opportunity is found.",
        "impact": "Sadly, due to the European law about sport betting, where the bookmakers have to redistribute exactly 85% of the money betted, the margin is much higher than in the US or UK market, and the opportunities are really rare. I only found 2 opportunities in 3 months of running the bot.",
        "customComponent": false,
        "objectFit": "object-cover"
  },
    "publibike": {
        "id": "publibike",
        "title": "Publibike",
        "description": "Inspired by the work of a French Youtuber, I wanted to analyze the data of the Publibike system in Switzerland, so that you can find the best publibike to take when at a certain location.",
        "shortDescription": "Inspired by the work of a French Youtuber, I wanted to analyze the data of the Publibike system in Switzerland, so that you can find the best publibike to take when at a certain location.",
        "detailedDescription": "The youtuber 'Data is Beautiful' made a video about the Velib system in Paris, where he fetched in real time data during 3 years, allowing him to analyze which Velib is the best when you are at a certain location, thanks to a algorithm of ranking based on the last 6 hours of utilization. I wanted to do the same with Publibike.",
        "category": "TBD",
        "categoryClass": "badge-primary",
        "gradient": "linear-gradient(135deg, #059669 0%, #065f46 100%)",
        "image": "/images/projects/publibike.png",
        "technologies": ["TBD"],
        "year": "2025",
        "github": "https://github.com/publibike-dashboard",
        "demo": null,
        "externalLink": null,
        "status": "Completed",
        "features": [
        "Real-time data analysis",
        "Ranking algorithm based on utilization",
        "Location-based recommendations",
        "Big Data Management System"
        ],
        "technicalDetails": "The project involves fetching real-time data from the Publibike API, analyzing it to determine the best bike to take based on location and usage patterns. The ranking algorithm takes into account the last 6 hours of utilization data to provide accurate recommendations. After that, I created a dashboard to know at which time to leave a place to be sure to have a publibike in the next station, based on the last month, last week or last day.",
        "impact": "With more than 500 millions lines of data, I managed to create a dashboard where you could see at which time you should leave a place to be sure to have a publibike in the next station.",
        "customComponent": false
  },
    "salles-libres-v2": {
        "id": "salles-libres-v2",
        "title": "Salles Libres V2",
        "description": "Salles Libres V2 is my first full stack app, where students could share documents about their courses.",
        "shortDescription": "Salles Libres V2 is my first full stack app, where students could share documents about their courses.",
        "detailedDescription": "Salles Libres V2 is my first full stack app, where students could share documents about their courses. It was constructed using MERN (mongo, express, react, node), a combo that allowed me to learn a lot and really start full stack development.",
        "category": "Website",
        "categoryClass": "badge-primary",
        "gradient": "linear-gradient(135deg, #059669 0%, #065f46 100%)",
        "image": "/images/projects/salles-libres-v2.jpg",
        "technologies": ["React", "Node.js", "Express", "MongoDB", "Full Stack Development"],
        "year": "2025",
        "github": "https://github.com/tomasoignons/salleslibres-api",
        "demo": null,
        "externalLink": null,
        "status": "Completed",
        "features": [
        "Document upload system",
        "Discord Database (yes, you read it correctly)",
        "User authentification and authorization system",
        "Responsible design for mobile and desktop",
        "100+ type of documents supported",
        "Restrictive Accessibility to the users of an organization"
        ],
        "technicalDetails": "The project was constructed around MongoDB database for normal storage, and a Discord storage system for the documents, to avoid paying for storage. The documents were sent on a private server, by the discord unofficial API, and retrieved the same way. The backend was made with Express and Node.js, and the frontend with React. The app was deployed different free services, which made it very very slow in production, but it was fast in development.",
        "impact": "Shared with a few friends, we started using it to share documents and course notes. It was less used than the initial Salles Libres project, but it was a great learning experience for me.",
        "customComponent": false,
        "objectFit": "object-cover"
  },
    "pix-instagram": {
        "id": "pix-instagram",
        "title": "Pix Instagram",
        "description": "Lorem Ipsum",
        "shortDescription": "Lorem Ipsum",
        "detailedDescription": "Lorem Ipsum",
        "category": "TBD",
        "categoryClass": "badge-primary",
        "gradient": "linear-gradient(135deg, #059669 0%, #065f46 100%)",
        "image": null,
        "technologies": ["TBD"],
        "year": "2025",
        "github": null,
        "demo": null,
        "externalLink": null,
        "status": "Completed",
        "features": [
        "TBD"
        ],
        "technicalDetails": "TBD",
        "impact": "TBD",
        "customComponent": false
  },
    "saas-builder": {
        "id": "saas-builder",
        "title": "SaaS Builder",
        "description": "After building a few softwares, I wanted to create a boilerplate to create SaaS really quickly, with all the features you need to launch a SaaS.",
        "shortDescription": "After building a few softwares, I wanted to create a boilerplate to create SaaS really quickly, with all the features you need to launch a SaaS.",
        "detailedDescription": "After building a few softwares, I wanted to create a boilerplate to create SaaS really quickly, with all the features you need to launch a SaaS, and with my favorite tech stack at the time, which was svelte, postgresql, stripe, node.js and express.",
        "category": "TBD",
        "categoryClass": "badge-primary",
        "gradient": "linear-gradient(135deg, #059669 0%, #065f46 100%)",
        "image": "/images/projects/saas-builder.jpeg",
        "technologies": ["React", "Node.js", "Express", "PostgreSQL", "Stripe", "SaaS Development"],
        "year": "2024",
        "github": null,
        "demo": null,
        "externalLink": null,
        "status": "Completed",
        "features": [
        "User authentification and password reset system",
        "Subscribtion management with Stripe integration",
        "Real time chat system between users",
        "Admin dashboard to manage users and subscriptions",
        "Responsive design for mobile and desktop"
        ],
        "technicalDetails": "This project was really interesting to work on, as I had to think about all the features that are needed to launch a SaaS, and how to make them work together. The frontend is built with Svelte, and the backend with Node.js and Express. The database is PostgreSQL, and Stripe is used for payment processing. The difficult part was to implement the chat in real time using websockets, as I had never done it before. Then, I discovered vue, nuxt and supabase, so I stopped the development of this project to focus on learning these new technologies.",
        "impact": "This project was usefull to get familiar with websockets, and to learn how to build a SaaS from scratch. I never used it to launch a SaaS, but I learned a lot by building it.",
        "customComponent": false,
        "objectFit": "object-cover"
  },
    "bauhaus": {
        "id": "bauhaus",
        "title": "Bauhaus",
        "description": "For a german course, we had to present a bauhaus object. Naturally, I created a website to present it.",
        "shortDescription": "For a german course, we had to present a bauhaus object. Naturally, I created a website to present it.",
        "detailedDescription": "For a german course, we had to present a bauhaus object. I developed the object in 3d using spline, and used a website to present it to the class.",
        "category": "Website",
        "categoryClass": "badge-primary",
        "gradient": "linear-gradient(135deg, #059669 0%, #065f46 100%)",
        "image": "/images/projects/bauhaus.jpeg",
        "technologies": ["Spline", "Three.js", "Web Development", "3D Modeling"],
        "year": "2025",
        "github": null,
        "demo": null,
        "externalLink": null,
        "status": "Completed",
        "features": [
        "Complete 3D model of a bauhaus object",
        "Interactive website to present the object"
        ],
        "technicalDetails": "Using React and the Spline functionalities, integrating a custom object is a bit tricky, but it is really fun to work with. The website is a single page application, with a 3D model of the object in the center, and some text around it to explain the concept.",
        "impact": "We got one of the best grade of the class for this project (19/20), and the class really appreciated it.",
        "customComponent": false,
        "objectFit": "object-cover"
  },
    "constance": {
        "id": "constance",
        "title": "Constance",
        "description": "To ask a girl for prom, I created a website to ask her. It was a huge failure.",
        "shortDescription": "To ask a girl for prom, I created a website to ask her. It was a huge failure.",
        "detailedDescription": "To ask a girl for prom, I created a website to ask her. It was a failure in the sense someone was quicker than me to ask her, but the said she would have said yes otherwise.",
        "category": "Website",
        "categoryClass": "badge-primary",
        "gradient": "linear-gradient(135deg, #059669 0%, #065f46 100%)",
        "image": "/images/projects/constance.jpg",
        "technologies": ["React"],
        "year": "2025",
        "github": null,
        "demo": null,
        "externalLink": null,
        "status": "Completed",
        "features": [
        "Interactive letters that reveal the message time after time"
        ],
        "technicalDetails": "The goal was to have a message asking her out, but with the letters appearing every 20 minutes (so the message will take 36 hours to appear), with my name in the end. The website is made with React, and the letters are revealed using a simple state management.",
        "impact": "She said no because she already had someone asking her out, but she said she would have said yes otherwise. In the end, I went with another girl.",
        "customComponent": false,
        "objectFit": "object-cover"
  },
    "my-homelab": {
        "id": "my-homelab",
        "title": "My Home Lab",
        "description": "This will require more than a paragraph to explain, but I basically have my own datacenter at home",
        "shortDescription": "Probably one of my biggest project. I basically have a datacenter at home, and this website is hosted on it, as well as my whole life",
        "detailedDescription": "This will require more than a paragraph to explain, but I basically have my own datacenter at home, with multiple servers, a NAS, a network infrastructure with multiple VLANs, a firewall, a VPN, and a lot of other things. I use it to host my website, my bots, my home automation system, and a lot of other things.",
        "category": "Homelab",
        "categoryClass": "badge-primary",
        "gradient": "linear-gradient(135deg, #059669 0%, #065f46 100%)",
        "image": "/images/projects/homelab.jpeg",
        "technologies": ["Docker", "Proxmox", "Kubernetes", "Home Automation", "Networking", "VLANs", "VPN", "Firewalls", "pfSense", "Home Assistant", "Google APIs", "Nginx"],
        "year": "2025",
        "github": null,
        "demo": null,
        "externalLink": null,
        "status": "Completed",
        "features": [
        "30+ self hosted services",
        "7TB of storage",
        "154Gb of RAM",
        "8 flatmates asking why you have a strange noise next to the storage room",
        "SubNetwork Infrastructure inside a Network Infrastructure",
        "Multiple VLANs to separate the traffic",
        "VPN to access the home lab from anywhere in the world",
        "Firewall to protect the home lab from the internet",
        "Automated backups of the whole system",
        "Home Automation system to control the lights, the heating, the music, and a lot of other things in the house",
        "Custom DNS server to manage the local domain and the external domain",
        "Monitoring system to monitor the whole system"
        ],
        "technicalDetails": "Kubernetes, Docker and Proxmox run the whole system",
        "impact": "This is a costly hobby...",
        "customComponent": false,
        "objectFit": "object-cover"
  },
    "uberclone": {
        "id": "uberclone",
        "title": "Uber Clone",
        "description": "To learn how to make Mobile Applications using React Native, I created an Uber Clone.",
        "shortDescription": "To learn how to make Mobile Applications using React Native, I created an Uber Clone.",
        "detailedDescription": "To learn how to make Mobile Applications using React Native, I created an Uber Clone. The app allows users to book rides, see their ride history, and manage their profile, as well as a custom map with the position of the user and the car he ordered.",
        "category": "Mobile App",
        "categoryClass": "badge-primary",
        "gradient": "linear-gradient(135deg, #059669 0%, #065f46 100%)",
        "image": "/images/projects/uberclone.jpeg",
        "technologies": ["React Native", "Expo", "Google Maps API"],
        "year": "2025",
        "github": null,
        "demo": null,
        "externalLink": null,
        "status": "Completed",
        "features": [
        "Real-time location tracking",
        "Ride history management",
        "User profile management",
        "Custom map integration"
        ],
        "technicalDetails": "Built with React Native, Expo, and Google Maps API",
        "impact": "This project helped me understand mobile app development better.",
        "customComponent": false,
        "objectFit": "object-cover"
  },
    "snakeAI": {
        "id": "snakeAI",
        "title": "Snake AI",
        "description": "During my first year at EPFL, I wanted to do a project on AI, and I chose to recode a snake AI with reinforcement learning.",
        "shortDescription": "During my first year at EPFL, I wanted to do a project on AI, and I chose to recode a snake AI with reinforcement learning.",
        "detailedDescription": "During my first year at EPFL, I wanted to do a project on AI, and I chose to recode a snake AI with reinforcement learning. The AI learns to play the game of snake by itself, using a neural network and reinforcement learning techniques.",
        "category": "Machine Learning",
        "categoryClass": "badge-primary",
        "gradient": "linear-gradient(135deg, #059669 0%, #065f46 100%)",
        "image": "/images/projects/snakeAI.png",
        "technologies": ["Python", "TensorFlow", "Keras", "PyGame", "Reinforcement Learning"],
        "year": "2025",
        "github": null,
        "demo": null,
        "externalLink": null,
        "status": "Completed",
        "features": [
        "Reinforcement learning algorithm",
        "Neural network implementation",
        "Game environment using PyGame",
        "Training and evaluation of the AI"
        ],
        "technicalDetails": "Built with Python, TensorFlow, Keras, and PyGame. The AI uses a deep Q-learning algorithm to learn how to play the game. The game environment is created using PyGame, and the AI is trained and evaluated using various techniques (final score, final position...).",
        "impact": "On a grid of 10x10, the AI managed to get a score of 35 and higher, which is what a normal player will have.",
        "customComponent": false
  },
    "togoodtogobot": {
        "id": "togoodtogobot",
        "title": "ToGoodToGo Bot",
        "description": "I often use to good to go to do my groceries, but the good deals are often taken really really quickly (it is a matter of seconds). I created a bot to help me have the best deals 100% of the time.",
        "shortDescription": "A bot to get the best deals on ToGoodToGo.",
        "detailedDescription": "I often use to good to go to do my groceries, but the good deals are often taken really really quickly (it is a matter of seconds). I created a bot to help me have the best deals 100% of the time. With a friend, we had to reverse engineer the app to get access to the REST API, because to good to go doesn't have a public API or a website to easily reverse ingeneer. The bot uses the API to determine when a predefined deal will be available again (to the second), and automatically books it, at the second it is available, giving no chance to a normal user.",
        "category": "Bots",
        "categoryClass": "badge-primary",
        "gradient": "linear-gradient(135deg, #059669 0%, #065f46 100%)",
        "image": "/images/projects/togoodtogo.png",
        "technologies": ["Python", "Requests", "API Reverse Engineering", "Automation", "Notification System", "Reverse Proxy"],
        "year": "2025",
        "github": null,
        "demo": null,
        "externalLink": null,
        "status": "Completed",
        "features": [
        "Automatic deal booking",
        "Real-time deal availability tracking",
        "Reverse engineered API access",
        "Proxy system reverse engineer the app",
        "Telephone rooting to access the https requests"
        ],
        "technicalDetails": "The biggest challenge of this project was to reverse engineer the app to get access to the API. We had to root a phone (which mean, install a full custom OS), and install a proxy system to be able to see the https requests. After that, it was easy to use the requests library to fetch the data and book the deals automatically, reproducing exactly the same requests as the app. A lot of existing projects on github just do a notification system, without active booking, but we managed to setup a full booking system with cron jobs scheduling to run at the second the deal is available for the next day.",
        "impact": "I have now a full root access to my phone, thanks to this project, and I learnt a lot about how to install custom OS on a phone and reverse engineer an app. My phone is now free from the chinese surveillance system (I had a Xiaomi custom android, which was really slow). I also managed to get the best deals on ToGoodToGo 100% of the time, which is really usefull when you are a student and want to eat well for cheap.",
        "customComponent": false
  },
    "groceries-application": {
        "id": "groceries-application",
        "title": "Groceries Application",
        "description": "To work with the to good to go bot, I created a groceries application to manage my groceries stock, and create a shopping list automatically when I am running low on an item.",
        "shortDescription": "To work with the to good to go bot, I created a groceries application to manage my groceries stock, and create a shopping list automatically when I am running low on an item.",
        "detailedDescription": "To interact with the to good to go bot, I created a groceries application to manage my groceries stock, and create a shopping list automatically when I am running low on an item. The app allows me to add items to my stock, and when an item is running low, it automatically adds it to a shopping list. The app also have an interface plugged into my to good to go account, allowing me to ask my bot to take an order for me the next day.",
        "category": "TBD",
        "categoryClass": "badge-primary",
        "gradient": "linear-gradient(135deg, #059669 0%, #065f46 100%)",
        "image": "/images/projects/groceries-application.jpeg",
        "technologies": ["React Native", "Expo"],
        "year": "2025",
        "github": null,
        "demo": null,
        "externalLink": null,
        "status": "Completed",
        "features": [
        "Automatic Item tracking",
        "Shopping list generation",
        "ToGoodToGo account integration"
        ],
        "technicalDetails": "The project is not trully finished, as the to good to go bot was never deployed other than locally, but the interface is ready to be used. The app stores everything inside a local storage, and you can keep track of the different items you have in your stock, and the app will automatically add them to a shopping list when you are running low on an item.",
        "impact": "I used this app at the beginning of my studies, to keep track of my groceries, and not forget to buy something when I was at the store. It proved to be a bit painful to always register the items I was using, so I stopped using it after a few weeks.",
        "customComponent": false,
        "objectFit": "object-cover"
  },
    "epfl-people-scrapper": {
        "id": "epfl-people-scrapper",
        "title": "EPFL People Scrapper",
        "description": "When looking for a flat in Lausanne, I choosed to filter a list of student in a student residence to find the ones that were going in exchange, so that I could sublet their flat.",
        "shortDescription": "When looking for a flat in Lausanne, I choosed to filter a list of student in a student residence to find the ones that were going in exchange, so that I could sublet their flat.",
        "detailedDescription": "When looking for a flat in Lausanne, I went to a student residence which was really good, took a photo of the mailboxes, and scrapped the names of the students living there, to see if any of them were potentially going in exchange, and could sublet their flat. I created a bot that scrapped the EPFL people directory, to get their e-mail address, so that I could sent them an email.",
        "category": "Bots",
        "categoryClass": "badge-primary",
        "gradient": "linear-gradient(135deg, #059669 0%, #065f46 100%)",
        "image": "/images/projects/epfl-people-scrapper.jpg",
        "technologies": ["Python", "Requests", "BeautifulSoup", "Web Scraping", "Automation"],
        "year": "2025",
        "github": null,
        "demo": null,
        "externalLink": null,
        "status": "Completed",
        "features": [
        "Automatic scrapping of the EPFL people directory"
        ],
        "technicalDetails": "The bot is just a simple script that takes a JSON as an input, checks if the person is in 2nd year of their Bachelor (3rd year students can't go in exchange), by scrapping the EPFL people directory to get their e-mail address. The bot was made in Python, using requests to fetch the data, and beautifulsoup to parse the HTML.",
        "impact": "I managed to get a sublocation of one year (which was exactly what I needed), in the cheapest residence of Lausanne, located at 10 minutes of the EPFL campus.",
        "customComponent": false,
        "objectFit": "object-cover"
  },
    "midjourney-instagram": {
        "id": "midjourney-instagram",
        "title": "Midjourney Instagram",
        "description": "Lorem Ipsum",
        "shortDescription": "Lorem Ipsum",
        "detailedDescription": "Lorem Ipsum",
        "category": "TBD",
        "categoryClass": "badge-primary",
        "gradient": "linear-gradient(135deg, #059669 0%, #065f46 100%)",
        "image": null,
        "technologies": ["TBD"],
        "year": "2025",
        "github": null,
        "demo": null,
        "externalLink": null,
        "status": "Completed",
        "features": [
        "TBD"
        ],
        "technicalDetails": "TBD",
        "impact": "TBD",
        "customComponent": false
  },
    "gurk": {
        "id": "gurk",
        "title": "Gurk",
        "description": "Gurk is a custom chrome extension that customize the Google Chrome homepage, with custom components, background and integration with other services.",
        "shortDescription": "Gurk is a custom chrome extension that allows users to personalize their Google Chrome homepage.",
        "detailedDescription": "Gurk is a custom chrome extension that allows users to personalize their Google Chrome homepage with various components, backgrounds, and integrations with other services.",
        "category": "TBD",
        "categoryClass": "badge-primary",
        "gradient": "linear-gradient(135deg, #059669 0%, #065f46 100%)",
        "image": null,
        "technologies": ["React", "Node.js", "Express", "PostgreSQL", "Chrome Extension Development", "Stripe"],
        "year": "2025",
        "github": null,
        "demo": null,
        "externalLink": null,
        "status": "Completed",
        "features": [
        "Full custom authentification system",
        "Subscribtion management with Stripe integration",
        "Multiple custom components (weather, todo list, notes, bookmarks, clock...)",
        "Custom background management",
        "36Md+ of combinations",
        "50+ users"
        ],
        "technicalDetails": "The app was initially built to be fully serverless, using only React and local storage, and some weird hacks to have a google calendar integration. After a few months, some friends wanted me to have it too, so I decided to recreate it from scratch, using a proper backend with Node.js, Express and PostgreSQL, to have a full custom authentification system, and a subscribtion management with Stripe integration. The frontend is built with React, and the app is on the chrome web store. It was the first time I deployed anything with a RestAPI, so I also took my first server and learned how to deploy a full stack app.",
        "impact": "To this day, this is the project where I spent the most time on (500+ hours), and the one I am the most proud of, because I did it mostly without any kind of vibe coding, only going throught the documentation and learning by myself. This is the project that allows me today to know what I am doing when I am using any AI tool to code, because I know how everything works behind the scene. ",
        "customComponent": false
  },
    "eth-elink": {
        "id": "eth-elink",
        "title": "Eth E-Link",
        "description": "In ETH, I often have to go from Honggerberg Campus to Zentrum Campus, and to do so, I use the e-link. The issue is that the schedules are in some kind of PDF and depends on the date. I created an app where I could have them easily on my phone.",
        "shortDescription": "In ETH, I often have to go from Honggerberg Campus to Zentrum Campus, and to do so, I use the e-link. The issue is that the schedules are in some kind of PDF and depends on the date. I created an app where I could have them easily on my phone.",
        "detailedDescription": "In ETH, I often have to go from Honggerberg Campus to Zentrum Campus, and to do so, I use the e-link. The issue is that the schedules are in some kind of PDF and depends on the date. I created an app where I could have them easily on my phone. The app has all the schedules, and it can display them to you, without even being connected to Internet.",
        "category": "Mobile App",
        "categoryClass": "badge-primary",
        "gradient": "linear-gradient(135deg, #059669 0%, #065f46 100%)",
        "image": "/images/projects/eth-elink.jpg",
        "technologies": ["React Native", "Expo"],
        "year": "2025",
        "github": null,
        "demo": null,
        "externalLink": null,
        "status": "Completed",
        "features": [
        "Offline access to schedules",
        "Easy to use interface",
        "All schedules available"
        ],
        "technicalDetails": "The app was built using React Native and Expo, allowing for a smooth development process and easy deployment on both iOS and Android devices. The schedules are stored locally on the device, enabling offline access.",
        "impact": "This app has significantly improved my daily commute, allowing me to easily access bus schedules without needing an internet connection. It has also been a valuable learning experience in mobile app development.",
        "customComponent": false,
        "objectFit": "object-cover"
  },
    "deliverooclone": {
        "id": "deliverooclone",
        "title": "Deliveroo Clone",
        "description": "When trying to learn new technologies, I often try to recreate existing apps. This time, I tried to recreate Deliveroo, a food delivery app.",
        "shortDescription": "A clone of the popular food delivery app.",
        "detailedDescription": "This project involved recreating the core features of Deliveroo, including restaurant listings, food ordering, and real-time tracking of deliveries. The goal was to understand the architecture and technologies used in modern web applications.",
        "category": "Mobile App",
        "categoryClass": "badge-primary",
        "gradient": "linear-gradient(135deg, #059669 0%, #065f46 100%)",
        "image": "/images/projects/deliverooclone.png",
        "technologies": ["React Native", "Expo"],
        "year": "2025",
        "github": null,
        "demo": null,
        "externalLink": null,
        "status": "Completed",
        "features": [
        "Real-time tracking of deliveries",
        "User-friendly interface",
        "Restaurant listings"
        ],
        "technicalDetails": "The app was built using React Native and Expo, allowing for a smooth development process and easy deployment on both iOS and Android devices. There is no backend, everything is hardcoded. The goal was to learn React-Native and Expo.",
        "impact": "This project has deepened my understanding of mobile app development, and helped me become more proficient with React Native and Expo.",
        "customComponent": false,
        "objectFit": "object-cover"
  },
    "salleslibres": {
        "id": "salleslibres",
        "title": "Salles Libres",
        "description": "Salles Libres is my first coding project, and it is quite nice. It is a website/mobile application that shows the free rooms in my highschool.",
        "shortDescription": "Salles Libres is my first coding project, and it is quite nice. It is a website/mobile application that shows the free rooms in my highschool.",
        "detailedDescription": "In my school, we had a lot of free time, and often with some friends, we struggled to find a room. We would have to check the rooms one by one until we found one that were free. I created a mobile application and  website that displayed the free rooms in real time, using the school timetables.",
        "category": "Web App",
        "categoryClass": "badge-primary",
        "gradient": "linear-gradient(135deg, #059669 0%, #065f46 100%)",
        "image": null,
        "technologies": ["TBD"],
        "year": "2025",
        "github": "https://github.com/tomasoignons/salles_libres",
        "demo": null,
        "externalLink": null,
        "status": "Completed",
        "features": [
        "TBD"
        ],
        "technicalDetails": "TBD",
        "impact": "TBD",
        "customComponent": false
  },
    "runfaker": {
        "id": "runfaker",
        "title": "Run Faker",
        "description": "Run Faker is a complete SaaS project, created to provide user the ability to generate fake runs to upload to Srava, for various reasons (testing, cheating...).",
        "shortDescription": "Run Faker is a complete SaaS project, created to provide user the ability to generate fake runs to upload to Srava, for various reasons (testing, cheating...).",
        "detailedDescription": "Run Faker is a complete SaaS project, created to provide user the ability to generate fake runs to upload to Srava, for various reasons (testing, cheating...). The app allows users to create a run by specifying the distance, duration, elevation gain, and other parameters. The app then generates a GPX file that can be uploaded to Strava.",
        "category": "Website",
        "categoryClass": "badge-primary",
        "gradient": "linear-gradient(135deg, #059669 0%, #065f46 100%)",
        "image": "/images/projects/runfaker.jpeg",
        "technologies": ["Vue.js", "Supabase", "NuxtJS", "Stripe", "Strava API"],
        "year": "2025",
        "github": null,
        "demo": "https://runfaker.com",
        "externalLink": null,
        "status": "Completed",
        "features": [
        "custom GPX file generation",
        "Full user authentification system",
        "Subscribtion management with Stripe integration",
        "GPX editor to customize the run",
        "Path finding algorithms to create a run between two points",
        "AI model to make a run look more realistic"
        ],
        "technicalDetails": "The project was inspired by the rise of what is called 'Strava Jockeys', people who are paid by other people to do their runs for them, and upload them to Strava. The app was built using NuxtJS, and Supabase for the database. It also implement a fully custom CI/CD pipeline to automatically deploy the app on my homelab at every push.",
        "impact": "We managed to sneak inside a constest organized by a big influencer, (the goal was to do the best time on a specific segment). Neither the influencer nor Strava managed to detect that the bike ride was fake, and we won the contest (along with a friend). The website has more than 50 users (which are not people I know), and has generated over 100 rides.",
        "customComponent": false,
        "objectFit": "object-cover"
  },
    "homeassistant": {
        "id": "homeassistant",
        "title": "Home Assistant",
        "description": "In my room, I wanted to have custom screens that would display useful information, like the weather, the time, my calendar, the news, the state of the train traffic in Switzerland, and a lot of other things. I created a home automation system using Home Assistant and a Google Home to have a voice control over these screens.",
        "shortDescription": "In my room, I wanted to have my custom screens to display useful informations. I created a home automation system using Home Assistant and a Google Home to have a voice control over these screens.",
        "detailedDescription": "In my room, I wanted to have custom screens that would display useful information, like the weather, the time, my calendar, the news, the state of the train traffic in Switzerland, and a lot of other things. I created a home automation system using Home Assistant and a Google Home to have a voice control over these screens. The screens run on an ubuntu computer, that implement a small webserver that recieves requests from Home Assistant to change the screen displayed.",
        "category": "Automation",
        "categoryClass": "badge-primary",
        "gradient": "linear-gradient(135deg, #059669 0%, #065f46 100%)",
        "image": "/images/projects/homeassistant.svg",
        "technologies": ["Home Assistant", "Express", "Node.js", "Python", "APIs", "Web Development", "Google APIs"],
        "year": "2025",
        "github": null,
        "demo": null,
        "externalLink": null,
        "status": "Completed",
        "features": [
        "Full voice control using Google Home",
        "Custom screens displaying useful information",
        "Home Assistant integration",
        "Automated routines"
        ],
        "technicalDetails": "The project was built using Home Assistant, a popular open-source home automation platform. I had to link my Google Home to Home Assistant, which was really tricky to do. Then, I setup a webserver on an ubuntu computer to display on the two screens in my room. The webserver recieves requests from Home Assistant throught a cloudlfare tunnel to change the screen displayed. It goes to a specific URL for each screen, scroll if necessary, to arrive at the desired information I want.",
        "impact": "The home automation system has significantly improved my daily routine by providing easy access to important information at a glance. It has also served as a proof of concept for further automation projects in my home, like an automated vacuum cleaner and a smart lighting system.",
        "customComponent": false
  },
    "spca": {
        "id": "spca",
        "title": "SPCA",
        "description": "In ETHZ, I am doing a job as a Student Assistant at the SPCA (System Programing and Computer Architecture) course. I am animating an exercise session, which mean I have to present the slides and do more advanced concepts explanations. To help the students, I setup a small wikiJS instance, where I put all the resources that I have given to them during the semester.",
        "shortDescription": "In ETHZ, I am doing a job as a Student Assistant at the SPCA (System Programing and Computer Architecture) course. To help the students, I setup a small wikiJS instance, where I put all the resources needed.",
        "detailedDescription": "In ETHZ, I am doing a job as a Student Assistant at the SPCA (System Programing and Computer Architecture) course. I am animating an exercise session, which mean I have to present the slides and do more advanced concepts explanations. To help the students, I setup a small wikiJS instance, where I put all the resources that I have given to them during the semester. The instance is accessible to everyone, and is hosted on my homelab.",
        "category": "Website",
        "categoryClass": "badge-primary",
        "gradient": "linear-gradient(135deg, #059669 0%, #065f46 100%)",
        "image": null,
        "technologies": ["Docker", "Kubernetes", "WikiJS"],
        "year": "2025",
        "github": null,
        "demo": null,
        "externalLink": null,
        "status": "Completed",
        "features": [
        "TBD"
        ],
        "technicalDetails": "TBD",
        "impact": "TBD",
        "customComponent": false
  },
    "finances": {
        "id": "finances",
        "title": "Finances",
        "description": "To help me with my finances, I created a web application to have a lot of graphs with chartJS, and to track my expenses and incomes.",
        "shortDescription": "To help me with my finances, I created a web application to have a lot of graphs with chartJS, and to track my expenses and incomes.",
        "detailedDescription": "To help me with my finances, I created a web application to have a lot of graphs with chartJS, and to track my expenses and incomes. The app allows me to visualize my financial data and gain insights into my spending habits.",
        "category": "Web App",
        "categoryClass": "badge-primary",
        "gradient": "linear-gradient(135deg, #059669 0%, #065f46 100%)",
        "image": "/images/projects/finances.png",
        "technologies": ["Chart.js", "Vue.js", "Supabase"],
        "year": "2025",
        "github": null,
        "demo": null,
        "externalLink": null,
        "status": "Completed",
        "features": [
        "Custom charts and graphs",
        "Custom selection of time range",
        "Double currency tracking (CHF and EUR)",
        "Double banking account tracking (in my case, Swiss and French account)",
        "Custom form to add expenses and incomes",
        "Data stored in Supabase for easy access and management"
        ],
        "technicalDetails": "The front-end is build with Vue.js, and the data is stored in Supabase, self hosted to be sure no one has access to this sensible information. The app uses Chart.js to create dynamic and interactive charts and graphs to visualize the financial data.",
        "impact": "This app has helped me better understand my spending habits and manage my finances more effectively. It has also been a valuable learning experience in web development and data visualization.",
        "customComponent": false,
        "objectFit": "object-cover"
  },
    "dynamatic": {
        "id": "dynamatic",
        "title": "Dynamatic",
        "description": "During the summer of 2025, I participated at the 'Summer at EPFL' program, which is an excellence research program. I worked on a project called Dynamatic, which goal was to create a dynamic HLS compiler, that would be able to optimize the generated code based on the input data.",
        "shortDescription": "During the summer of 2025, I participated at the 'Summer at EPFL' program, which is an excellence research program. I worked on a project called Dynamatic, which goal was to create a dynamic HLS compiler.",
        "detailedDescription": "Dynamatic is a project aimed at creating a dynamic HLS compiler capable of optimizing generated code based on input data. I worked on this huge project during the 'Summer at EPFL' program, an excellence research initiative. I mainly work on helping on the implementation of memory optimizations.",
        "category": "Research Project",
        "categoryClass": "badge-primary",
        "gradient": "linear-gradient(135deg, #059669 0%, #065f46 100%)",
        "image": "/images/projects/dynamatic.png",
        "technologies": ["C++", "Assembler", "HLS", "LLVM", "C"],
        "year": "2025",
        "github": "https://github.com/tomasoignons/dynamatic",
        "demo": null,
        "externalLink": null,
        "status": "Completed",
        "features": [
        "Optimizing Memory accesses using fast token delivery",
        "Implementing Buffer Placement algorithms",
        "Correct CDFCG generation (Choice Free Dataflow Control Graph)",
        "Implementing a custom memory model"
        ],
        "technicalDetails": "The project is mainly written in C++, with some parts in C and Assembler. The project is based on LLVM, and the goal is to create a custom HLS compiler that would be able to optimize the generated code based on the input data. The project is still ongoing.",
        "impact": "I managed to reduce memory latency by 20% on some benchmarks.",
        "customComponent": false,
        "objectFit": "object-cover"
  },
    "events-eth": {
        "id": "events-eth",
        "title": "Events ETH",
        "description": "At EPFL, I was used to go to events with free food. I wanted to have a list of all the ETH events with free food.",
        "shortDescription": "At EPFL, I was used to go to events with free food. I wanted to have a list of all the ETH events with free food, because I don't have my habits at ETH.",
        "detailedDescription": "This project aims to create a comprehensive list of all ETH events that offer free food. It involves gathering information about various events, their locations, and the type of food provided. It also includes the events of UZH, the University of Zürich near ETH. The goal is to have at least one event with free food every day of the week.",
        "category": "Website",
        "categoryClass": "badge-primary",
        "gradient": "linear-gradient(135deg, #059669 0%, #065f46 100%)",
        "image": "/images/projects/events-eth.jpg",
        "technologies": ["Vue.js"],
        "year": "2025",
        "github": "https://github.com/tomasoignons/events-eth",
        "demo": null,
        "externalLink": null,
        "status": "Completed",
        "features": [
        "Complete ETH and UZH events scrapping",
        "Custom algorithm to filter events with free food",
        "Mobile view optimization"
        ],
        "technicalDetails": "The app was done in Vue.js, and the events are scrapped from the ETH and UZH websites. The app uses a custom algorithm to filter the events with free food, and display them in a user-friendly way.",
        "impact": "The website helps me find events with free food easily, and I managed to go to at least one event with free food every one day out of two of the week.",
        "customComponent": false,
        "objectFit": "object-cover"
  },
    "meetings-booking-app": {
        "id": "meetings-booking-app",
        "title": "Meetings Booking App",
        "description": "At EPFL, I often had to give my availability for meetings. I created a small web application connected to my Google Calendar to allow people to book meetings with me.",
        "shortDescription": "At EPFL, I often had to give my availability for meetings. I created a small web application connected to my Google Calendar to allow people to book meetings with me.",
        "detailedDescription": "At EPFL, when I had to give my availabilities, it was often like 'from 2 to 3 and then from 5 to 6'. I could also not just do a sreenshot of my calendar, as there are a lot of private and personal events. I wanted user to just see my availability, without the details. This project involved creating a web application that integrates with Google Calendar to manage meeting bookings. Users can view my availability (the events listed as 'mandatory' in Google Calendar are the timeslots where I am not available) and book meetings directly through the app.",
        "category": "Website",
        "categoryClass": "badge-primary",
        "gradient": "linear-gradient(135deg, #059669 0%, #065f46 100%)",
        "image": "/images/projects/meeting-booking-app.jpg",
        "technologies": ["Vue.js", "Google APIs"],
        "year": "2025",
        "github": "https://github.com/tomasoignons/meeting-booking-app",
        "demo": null,
        "externalLink": null,
        "status": "Completed",
        "features": [
        "Google Calendar integration",
        "Real-time availability display",
        "Meeting booking system",
        "Email notifications for bookings"
        ],
        "technicalDetails": "The app was implemented using a service account, so that I don't need any kind of backend to handle it, and the information about my calendar is still private. The app uses the Google Calendar API to fetch my availability and manage bookings.",
        "impact": "The app makes the process of seeing my availability much easier, and I often use it not just to book meetings, but to let my friends see when I can hang out with them.",
        "customComponent": false,
        "objectFit": "object-cover"
  },
    "statslife": {
        "id": "statslife",
        "title": "StatsLife",
        "description": "In May, I discovered runfaker, which gather the gpx data from Strava, and shows on a map of the world where you have been. I wanted to do the same, but with my whole life.",
        "shortDescription": "In May, I discovered statshunter, which gather the gpx data from Strava, and shows on a map of the world where you have been. I wanted to do the same, but with my whole life.",
        "detailedDescription": "StatsLife is a personal project aimed at visualizing my life experiences on a global map. By leveraging various data sources, I wanted to create a comprehensive view of my travels, activities, and significant life events.",
        "category": "Data Analysis",
        "categoryClass": "badge-primary",
        "gradient": "linear-gradient(135deg, #059669 0%, #065f46 100%)",
        "image": "/images/projects/statslife.jpg",
        "technologies": ["Vue.js", "Supabase", "Leaflet"],
        "year": "2025",
        "github": "https://github.com/tomasoignons/statslife",
        "demo": null,
        "externalLink": null,
        "status": "Completed",
        "features": [
        "Global map visualization",
        "Multiple Transport Modes",
        "50000+ km traveled"
        ],
        "technicalDetails": "The app was built using Vue.js for the frontend, Supabase for data storage, and Leaflet for map visualization. I placed all the tiles (18000+) by hand, which was a bit painful, but the end result is a beautiful and interactive map showcasing my life's journey.",
        "impact": "The app allows me to visualize my life experiences in a unique way, helping me reflect on my travels and activities over the years. I also helps me see which regions/countries I didn't visit yet, and plan future trips accordingly.",
        "customComponent": false,
        "objectFit": "object-cover"
  },
  "datin": {
    "id": "datin",
    "title": "DatIN",
    "description": "Comprehensive data collection and analysis platform for Swiss companies. Gathered information on 2M+ businesses including contact details, industry classification, and business metrics for market research and business intelligence.",
    "shortDescription": "Data collection platform for 2M+ Swiss companies with email and phone analysis.",
    "detailedDescription": "DatIN represents a comprehensive data intelligence platform designed to collect, process, and analyze business information across Switzerland's corporate landscape. This project involved building a sophisticated data pipeline capable of handling massive datasets while maintaining accuracy and relevance.",
    "category": "Data Analysis",
    "categoryClass": "badge-primary",
    "gradient": "linear-gradient(135deg, #059669 0%, #065f46 100%)",
    "image": "/images/projects/datin.jpg",
    "technologies": ["Python", "Data Analysis", "Web Scraping", "APIs", "Supabase", "Pandas", "Scrapy"],
    "year": "2025",
    "github": null,
    "demo": null,
    "externalLink": "https://datin.ch",
    "status": "Completed",
    "features": [
      "Massive Scale Collection: Successfully gathered data on over 2 million Swiss companies",
      "Contact Information: Extracted and validated email addresses and phone numbers",
      "Industry Classification: Automated categorization using NACE codes and business descriptions",
      "Data Quality Assurance: Implemented validation algorithms to ensure data accuracy",
      "Export Capabilities: Multiple format support for business intelligence tools",
      "Cross Platform Integration: Extract data from each company's website"
    ],
    "technicalDetails": "The platform was built using Python as the core language, leveraging powerful libraries like Pandas for data manipulation and PostgreSQL for robust data storage. The web scraping component utilized multiple APIs and advanced crawling techniques to ensure comprehensive coverage while respecting rate limits and legal boundaries.",
    "impact": "DatIN has proven invaluable for market research, lead generation, and business intelligence applications. The comprehensive dataset enables users to identify market opportunities, analyze competitive landscapes, and make data-driven business decisions across various Swiss industries.",
    "customComponent": true
  },
  "memehater": {
    "id": "memehater",
    "title": "MemeHater",
    "description": "Advanced machine learning model for detecting hateful content in memes using state-of-the-art multimodal AI. Implemented VisualBERT architecture with custom fine-tuning using PyTorch and TensorFlow for enhanced accuracy in visual-textual content analysis.",
    "shortDescription": "ML model to detect hateful memes using VisualBERT, fine-tuned with PyTorch and TensorFlow.",
    "detailedDescription": "MemeHater addresses the critical challenge of detecting hateful content in multimodal social media content. This project combines cutting-edge computer vision and natural language processing techniques to create a robust system capable of understanding both visual and textual elements in memes.",
    "category": "Machine Learning",
    "categoryClass": "badge-secondary",
    "gradient": "linear-gradient(135deg, #0ea5e9 0%, #0284c7 100%)",
    "image": "/images/projects/memehater.jpg",
    "technologies": ["Python", "VisualBERT", "PyTorch", "TensorFlow", "Computer Vision", "NLP", "Transformers"],
    "year": "2024",
    "github": null,
    "demo": null,
    "externalLink": null,
    "status": "Completed",
    "features": [
      "VisualBERT Architecture: Implemented state-of-the-art multimodal transformer model",
      "Custom Fine-tuning: Adapted pre-trained models for hate speech detection",
      "Dual Framework Support: Leveraged both PyTorch and TensorFlow for optimal performance",
      "Vision-Language Understanding: Advanced cross-modal attention mechanisms",
      "Robust Evaluation: Comprehensive testing on diverse meme datasets"
    ],
    "technicalDetails": "The project involved extensive data preprocessing, feature extraction from both image and text modalities, and sophisticated model training techniques. The VisualBERT model was fine-tuned using transfer learning approaches, allowing it to understand the complex relationship between visual elements and textual content in memes.",
    "impact": "This work contributes to the growing field of multimodal AI and content moderation. The model demonstrates high accuracy in detecting subtle forms of hate speech that traditional text-only approaches might miss, making it valuable for social media platforms and content moderation systems.",
    "customComponent": true
  },
  "holybot": {
    "id": "holybot",
    "title": "HolyBot",
    "description": "Automated Telegram bot serving the student community with real-time discount aggregation and deal distribution. Successfully scaled to serve 1000+ active users with intelligent filtering, personalized recommendations, and automated deal verification systems.",
    "shortDescription": "Telegram bot distributing discounts and deals to 1000+ active student users.",
    "detailedDescription": "HolyBot was born from the need to help students find the best deals and discounts in their daily lives. What started as a small project quickly grew into a comprehensive platform serving over 1000 active users with personalized deal recommendations and real-time notifications.",
    "category": "Telegram Bot",
    "categoryClass": "badge-accent",
    "gradient": "linear-gradient(135deg, #f59e0b 0%, #d97706 100%)",
    "image": "/images/projects/holybot.jpg",
    "technologies": ["Node.js", "Telegram API", "Python", "Automation", "MongoDB", "Web Scraping"],
    "year": "2024",
    "github": null,
    "demo": null,
    "externalLink": "https://t.me/holybot",
    "status": "Active",
    "features": [
      "Real-time Deal Aggregation: Automated scraping from multiple deal websites",
      "Smart Filtering: AI-powered categorization and relevance scoring",
      "Personalized Recommendations: User preference learning and targeted notifications",
      "Deal Verification: Automated checking for deal validity and expiration",
      "User Engagement: Interactive commands and feedback collection",
      "Community Features: User-submitted deals and rating system"
    ],
    "technicalDetails": "The bot utilizes a robust Node.js backend integrated with the Telegram Bot API for seamless user interactions. Python scripts handle complex web scraping operations, while MongoDB stores user preferences, deal history, and analytics data. The system includes automated monitoring and failover mechanisms to ensure 24/7 availability.",
    "impact": "Starting with a small group of university friends, HolyBot has grown organically through word-of-mouth recommendations. The platform has helped students save thousands of euros collectively and has become an essential tool for budget-conscious shoppers. The success led to partnerships with local businesses and integration with student discount programs.",
    "customComponent": true
  },
  "mister-powerpoint": {
    "id": "mister-powerpoint",
    "title": "Mister PowerPoint",
    "description": "Educational content creation project focused on PowerPoint mastery and presentation design. Built a thriving Instagram community reaching 12k followers in under two months, creating viral content about presentation techniques, design principles, and professional tips.",
    "shortDescription": "Instagram account about PowerPoint tutorials reaching 12k followers in 2 months.",
    "detailedDescription": "Mister PowerPoint emerged from a passion for design and education, aiming to transform how people perceive and use presentation software. This content creation project focused on making PowerPoint accessible, engaging, and powerful for users of all skill levels.",
    "category": "Content Creation",
    "categoryClass": "badge-neutral",
    "gradient": "linear-gradient(135deg, #6366f1 0%, #4f46e5 100%)",
    "image": "/images/projects/mister-powerpoint.jpg",
    "technologies": ["Content Creation", "Design", "PowerPoint", "Social Media", "Adobe Creative Suite"],
    "year": "2022-2023",
    "github": null,
    "demo": null,
    "externalLink": "https://instagram.com/mister.powerpoint",
    "status": "Completed",
    "features": [
      "Educational Tutorials: Step-by-step guides for complex PowerPoint features",
      "Design Principles: Teaching visual hierarchy, typography, and color theory",
      "Template Creation: Professional templates for business and academic use",
      "Quick Tips: Bite-sized content for immediate improvement",
      "Before/After Showcases: Dramatic slide makeovers and transformations",
      "Trending Techniques: Latest design trends adapted for presentations"
    ],
    "technicalDetails": "Each post involved extensive research on presentation best practices, creation of original designs, and careful curation of educational content. The process included market analysis to understand what resonated with the audience, A/B testing different content formats, and continuous iteration based on engagement metrics.",
    "impact": "The project helped thousands of professionals, students, and entrepreneurs improve their presentation skills. Many followers reported significant improvements in their ability to communicate ideas visually, leading to better business outcomes and academic success. The content democratized professional design knowledge.",
    "customComponent": true
  },
  "disco-platform": {
    "id": "disco-platform",
    "title": "Disco Platform",
    "description": "Research project developing a decentralized private collaborative platform for machine learning workflows. Working on frontend improvements, reliability features, and user experience enhancements for distributed ML model training and collaboration.",
    "shortDescription": "Decentralized collaborative platform for machine learning with frontend improvements.",
    "detailedDescription": "Disco Platform represents a groundbreaking approach to collaborative machine learning, combining the power of decentralized computing with privacy-preserving technologies. This research project aims to democratize access to large-scale ML capabilities while maintaining data privacy and security.",
    "category": "Research Project",
    "categoryClass": "badge-info",
    "gradient": "linear-gradient(135deg, #8b5cf6 0%, #7c3aed 100%)",
    "image": "/images/projects/disco.jpg",
    "technologies": ["Vue.js", "Machine Learning", "Decentralized Systems", "Collaboration", "WebRTC", "Blockchain"],
    "year": "2024-2025",
    "github": "https://github.com/epfml/disco",
    "demo": null,
    "externalLink": "https://discolab.ai",
    "status": "In Progress",
    "features": [
      "Decentralized Architecture: Distributed computing network for ML training",
      "Privacy Preservation: Advanced cryptographic techniques for data protection",
      "Collaborative Workflows: Seamless multi-party model development",
      "Resource Optimization: Efficient allocation of computational resources",
      "Real-time Collaboration: Live model training and result sharing",
      "Accessibility Focus: User-friendly interface for non-technical users"
    ],
    "technicalDetails": "My role focuses on enhancing the user experience and frontend reliability of the platform. This includes developing intuitive interfaces for complex ML workflows, implementing real-time collaboration features, and ensuring the platform remains accessible to researchers with varying technical backgrounds.",
    "impact": "This work contributes to the advancement of federated learning, privacy-preserving machine learning, and collaborative research tools. The platform has the potential to accelerate ML research by enabling secure collaboration between institutions and researchers worldwide while protecting sensitive data.",
    "customComponent": true
  },
  "boundaryai-backend": {
    "id": "boundaryai-backend",
    "title": "BoundaryAI Backend",
    "description": "Leading backend development for innovative AI startup focused on automated feedback analysis and sentiment processing. Responsible for API architecture, survey analysis systems, data processing pipelines, and integration with machine learning models.",
    "shortDescription": "Backend development for AI startup focused on feedback analysis and survey systems.",
    "detailedDescription": "BoundaryAI represents the next generation of feedback analysis and sentiment processing technology. As the lead backend developer, I'm responsible for architecting and implementing the core systems that power the platform's AI-driven insights and analytics capabilities.",
    "category": "Startup",
    "categoryClass": "badge-warning",
    "gradient": "linear-gradient(135deg, #ec4899 0%, #db2777 100%)",
    "image": "/images/projects/boundaryai.jpg",
    "technologies": ["Node.js", "APIs", "AI Integration", "Database Design", "Express.js", "MongoDB", "Docker"],
    "year": "2025",
    "github": null,
    "demo": null,
    "externalLink": "https://boundaryai.com",
    "status": "In Progress",
    "features": [
      "API Architecture: Designing and implementing RESTful APIs for frontend integration",
      "Data Pipeline Management: Building robust data processing and transformation systems",
      "AI Model Integration: Seamlessly connecting machine learning models with backend services",
      "Database Optimization: Designing efficient database schemas and query optimization",
      "Survey Analysis Engine: Core algorithms for processing and analyzing feedback data",
      "Scalability Engineering: Ensuring system performance under high load conditions"
    ],
    "technicalDetails": "The backend is built on a modern Node.js stack with Express.js providing the API layer. MongoDB handles complex data relationships and analytics storage, while Docker ensures consistent deployment across development and production environments. The system is designed for horizontal scaling and includes comprehensive monitoring and logging capabilities.",
    "impact": "The platform enables businesses to gain deeper insights from customer feedback, employee surveys, and market research data. By automating the analysis process and providing actionable insights, BoundaryAI helps organizations make data-driven decisions faster and more effectively than traditional manual analysis methods.",
    "customComponent": true
  }
}